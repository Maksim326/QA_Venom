Introduction.
This proposal outlines the design and implementation of a QA Automation Test Framework for Data Flow testing. The framework ensures that each step in the pipeline is verified during execution. The framework is designed to be modular, scalable, and integrated with CI/CD.

Data Pipeline Execution with Tests

 


Objective
1.	Automation tests for key pipeline steps(file received, file upload, raw table validation, transformation steps)
2.	Centralize all test logic in a dedicated QA Automation Test Framework repository.
3.	Ensure that tests run only during CI/CD
4.	Use GitHub Actions for continuous integration and deployment
 


Overview 
The framework consists of:
-	QA  Automation Test Framework( not created yet)
-	Azure testing orchestration functions app
Tools
-	Python language for writing test scripts
-	Pytest for test execution and assertion
-	Schedular  for CI/CD automation
 
Implementation Steps:
-	Test files:
o	Test files will be stored in  test repo( or dedicated blob storage) and will be used for test execution
o	Test files will be uploaded to inbound folder (azure function will provide us information about test file location construct_event_data)
o	Use Correlation ID and file path to confirm  Test Data Flow and select correct raw/transformation tables 



Framework Benefits:
1.	Automation- GitHub Actions automates test execution and deployment
2.	Scalability - New tests can be added without modifying Production Code
3.	Modularity- All test Logic resides in QA  Automation Test Framework, reducing duplication
 






Data Flow(simplified)
 
 


 
 
 

